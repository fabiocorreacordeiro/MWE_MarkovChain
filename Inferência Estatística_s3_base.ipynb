{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infêrência Estatística\n",
    "# Título: Avaliação do impacto da expressões multipalavras nos modelos de linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import nltk\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseamos o código no Read me da biblioteca \"Markovify\" em: https://github.com/jsvine/markovify/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada arquivos do diretórios especificado lemos e preprocessamos o texto, criamos uma rede de markov com os n-grams (state_size) e combinamos os modelos de todos os arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, criamos uma função para preprocessar os textos\n",
    "def preprocess(text):\n",
    "    # Decodificar usando ISO 8859-1 \n",
    "    text = text.decode('ISO 8859-1')\n",
    "    # Colocar todas as letras em minúscula\n",
    "    text = text.lower()\n",
    "    # Separar as sentenças pelos pontos de finais\n",
    "    text = text.split('.')\n",
    "    new_text = []\n",
    "    for sent in text:\n",
    "        # Eliminamos as sentenças com menos de 100 caracteres\n",
    "        if len(sent)> 100:\n",
    "            # Excluir os espaços no início e fim das sentenças\n",
    "            new_text.append(sent.strip())\n",
    "    return(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 50 arquivos processados --- --- 17.889095067977905 seconds ---\n",
      "--- 100 arquivos processados --- --- 73.62001895904541 seconds ---\n",
      "--- 139.53809070587158 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Contador de tempo\n",
    "start_time = time.time()\n",
    "\n",
    "# Cadeia de Markov combinada\n",
    "combined_model = None\n",
    "\n",
    "# Contagem de arquivos\n",
    "n_files = 0\n",
    "\n",
    "# Iterar pelos diretórios e arquivos\n",
    "for (dirpath, _, filenames) in os.walk(\"Originais/treino\"):\n",
    "    for filename in filenames:\n",
    "        n_files += 1\n",
    "        \n",
    "        try:\n",
    "            # Ler o arquivo e criar uma cadeia de Markov para cada arquivo\n",
    "            with open(os.path.join(dirpath, filename), 'rb') as f:\n",
    "                # Preprocessar o texto lido\n",
    "                text = preprocess(f.read())\n",
    "                model = markovify.NewlineText(text, retain_original=False, state_size=3)\n",
    "\n",
    "                # Combinar modelo criado para um arquivo com a Cadeia de Markov combinada\n",
    "                if combined_model:\n",
    "                    combined_model = markovify.combine(models=[combined_model, model])\n",
    "                else:\n",
    "                    combined_model = model\n",
    "        except:\n",
    "            print(\"Não foi possível ler o arquivo\", filename)\n",
    "            #pass\n",
    "                    \n",
    "        # Contador de arquivos processados\n",
    "        if n_files % 50 == 0:\n",
    "            print (\"--- %s arquivos processados ---\" % n_files, \"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Fim do contador de tempo\n",
    "print (\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000a\u0000s\u0000 \u0000e\u0000x\u0000p\u0000e\u0000r\u0000i\u0000ê\u0000n\u0000c\u0000i\u0000a\u0000s\u0000 \u0000m\u0000o\u0000s\u0000t\u0000r\u0000a\u0000m\u0000 \u0000q\u0000u\u0000e\u0000 \u0000e\u0000m\u0000 \u00002\u00000\u00001\u00005\u0000 \u0000o\u0000 \u0000p\u0000e\u0000t\u0000r\u0000ó\u0000l\u0000e\u0000o\u0000 \u0000e\u0000 \u0000s\u0000e\u0000u\u0000 \u0000d\u0000e\u0000r\u0000i\u0000v\u0000a\u0000d\u0000o\u0000s\u0000 \u0000t\u0000e\u0000m\u0000 \u0000s\u0000i\u0000d\u0000o\u0000 \u0000i\u0000n\u0000d\u0000u\u0000b\u0000i\u0000t\u0000a\u0000v\u0000e\u0000l\u0000m\u0000e\u0000n\u0000t\u0000e\u0000 \u0000a\u0000s\u0000 \u0000 c\u0000o\u0000m\u0000m\u0000o\u0000d\u0000i\u0000t\u0000i\u0000e\u0000s\u0000 \u0000m\u0000a\u0000i\u0000s\u0000 \u0000n\u0000e\u0000r\u0000v\u0000o\u0000s\u0000a\u0000s\u0000 \u0000d\u0000e\u0000s\u0000t\u0000e\u0000 \u0000f\u0000i\u0000n\u0000a\u0000l\u0000 \u0000d\u0000e\u0000 \u0000s\u0000é\u0000c\u0000u\u0000l\u0000o\u0000;\u0000 \u0000d\u0000e\u0000s\u0000i\u0000n\u0000t\u0000e\u0000g\u0000r\u0000a\u0000ç\u0000ã\u0000o\u0000 \u0000t\u0000e\u0000m\u0000 \u0000e\u0000n\u0000c\u0000o\u0000r\u0000a\u0000j\u0000a\u0000d\u0000o\u0000 \u0000a\u0000 \u0000d\u0000e\u0000s\u0000i\u0000n\u0000t\u0000e\u0000g\u0000r\u0000a\u0000ç\u0000ã\u0000o\u0000 \u0000d\u0000e\u0000 \u0000a\u0000t\u0000i\u0000v\u0000i\u0000d\u0000a\u0000d\u0000e\u0000s\u0000,\u0000 \u0000f\u0000a\u0000z\u0000e\u0000n\u0000d\u0000o\u0000 \u0000c\u0000o\u0000m\u0000 \u0000q\u0000u\u0000e\u0000 \u0000e\u0000s\u0000s\u0000a\u0000 \u0000n\u0000ã\u0000o\u0000 \u0000s\u0000e\u0000j\u0000a\u0000 \u0000u\u0000m\u0000a\u0000 \u0000f\u0000a\u0000l\u0000h\u0000a\u0000 \u0000t\u0000ã\u0000o\u0000 \u0000g\u0000r\u0000a\u0000v\u0000e\u0000 \u0000q\u0000u\u0000a\u0000n\u0000t\u0000o\u0000 \u0000a\u0000 \u0000p\u0000r\u0000i\u0000m\u0000e\u0000i\u0000r\u0000a\u0000\n"
     ]
    }
   ],
   "source": [
    "# Imprimir um exemplo de sentença aleatória\n",
    "print(combined_model.make_sentence(max_words=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gravar modelo em JSON em disco\n",
    "model_json = combined_model.to_json()\n",
    "with open('MarkovChainModel_s3_base.json', 'w') as f:\n",
    "    json.dump(model_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo em JSON do disco\n",
    "with open('MarkovChainModel_s3_base.json', 'r') as f:\n",
    "    model_json = markovify.Text.from_json(json.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os textos usados são em português, foi necessário codificar em 'ISO 8859-1', já o modelo JSON está codificado em UTF16. Portanto, ao ler e consultar os termos do modelo é necessário usar a codificação correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe9 in position 26: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ce220b00a0dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#Criando sentença aleatória iniciando com as palavras sementes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_sentence_with_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xe9 in position 26: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Geração de sentença aleatória que iniciam com n-palavras\n",
    "\n",
    "# Palavras que serãao usadas como semente\n",
    "palavra_1 = 'a'\n",
    "palavra_2 = 'petrobras'\n",
    "palavra_3 = 'é'\n",
    "\n",
    "# Ajustando a codificação para ser usado no modelo\n",
    "palavra_1 = ' ' + palavra_1 + ' '\n",
    "palavra_2 = ' ' + palavra_2 + ' '\n",
    "palavra_3 = ' ' + palavra_3\n",
    "palavra_1 = palavra_1.encode('utf16')[3:]\n",
    "palavra_2 = palavra_2.encode('utf16')[3:]\n",
    "palavra_3 = palavra_3.encode('utf16')[4:]\n",
    "seed = palavra_1 + palavra_2 + palavra_3\n",
    "\n",
    "#Criando sentença aleatória iniciando com as palavras sementes\n",
    "print(combined_model.make_sentence_with_start(seed.decode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do modelo criado pela biblioteca Markovify, extraímos a cadeia de Markov e gravamos em um dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair cadeia de Markov do modelo\n",
    "chain = combined_model.to_dict()['chain']\n",
    "# Transformando a cadeia em um dicionário \n",
    "dic = {}\n",
    "for state in json.loads(chain):\n",
    "    dic[(state[0][0],state[0][1], state[0][2])] = state[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos uma função para consultar a cadeia de Markov. Dado duas palavras, extraímos as próximas palavras possíveis, a contagem delas no conjunto de treinamento e a soma total. Dessa forma conseguimos calcular  $p(x_3|x_2,x_1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que dado duas palavras, retorna um dicionários com as probabilidades das palavras seguintes\n",
    "def query_chain(palavra_1, palavra_2, palavra_3):\n",
    "    # Selecionar o dicionário cuja entrada é o par de palavras \"palavra_1\" e \"palavra_2\"\n",
    "    d = dic[(palavra_1, palavra_2, palavra_3)]\n",
    "    new_d = {}\n",
    "    # Transformar a contagem de palavras em probabilidade\n",
    "    for w in d:\n",
    "        new_d[w] = d[w]/sum(d.values())\n",
    "    return (new_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O calculamos a perplexidade para cada sentença. Dada as primeiras palavras, obtivemos do modelo a probabilidade da palavra seguinte. Em seguida, avançamos pela sentença recuperando as probablidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dada uma sentença, a função retorna uma lista com as entropias calculada para cada trio de palavras\n",
    "def entropy(sent):\n",
    "    # Quebra a sentença em tokens\n",
    "    words = nltk.word_tokenize(sent)\n",
    "    # Variável para guardar a entropia de cada conjunto de palavras\n",
    "    ln_prob_Xi = []\n",
    "    # Janela de iteração pela sentença\n",
    "    for w in range(len(words)-3):\n",
    "        # Cálculo a entropia\n",
    "        try:\n",
    "            ln_prob_Xi.append(- math.log(query_chain(words[w], words[w+1], words[w+2])[words[w+3]]))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return(np.mean(ln_prob_Xi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que recebe uma string com o caminho e nome da pasta com os arquivos e retorna a perplexidade\n",
    "\n",
    "def perplexity(dirpath):\n",
    "\n",
    "    # Início do contador de tempo\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Variável para armazenar as entropias\n",
    "    ent = []\n",
    "\n",
    "    # Contagem de arquivos\n",
    "    n_files = 0\n",
    "    # Iterando pelos arquivos da pasta indicada em\n",
    "    for (dirpath, _, filenames) in os.walk(dirpath):\n",
    "        \n",
    "        for filename in filenames:\n",
    "            n_files += 1\n",
    "            try:\n",
    "                # Ler o arquivo e calcular a entropia\n",
    "                with open(os.path.join(dirpath, filename), 'rb') as f:\n",
    "                    # Preprocessar o texto lido\n",
    "                    text = preprocess(f.read())\n",
    "                    #Calcular a entropia da sentença\n",
    "                    for sent in text:\n",
    "                        ent.append(entropy(sent))\n",
    "\n",
    "            except:\n",
    "                print(\"Não foi possível ler o arquivo\", filename)\n",
    "        \n",
    "                \n",
    "            # Contador de arquivos processados\n",
    "            if n_files % 5 == 0:\n",
    "                print (\"--- %s arquivos processados ---\" % n_files, \"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    \n",
    "    # Transformando a lista de entropias em uma np.array e excluir os valores \"nan\"\n",
    "    ent = np.array(ent)\n",
    "    ent = ent[~np.isnan(ent)]\n",
    "    \n",
    "    # Fim do contador de tempo\n",
    "    print (\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return (math.exp(np.mean(ent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\upe2\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5 arquivos processados --- --- 2.4339380264282227 seconds ---\n",
      "--- 10 arquivos processados --- --- 5.162765741348267 seconds ---\n",
      "--- 7.059710264205933 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.5635113240535405"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity(\"Originais/teste\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
